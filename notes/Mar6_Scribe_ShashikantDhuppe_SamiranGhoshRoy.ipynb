{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March 6, 2019 - Shashikant R. Dhuppe and Samiran Ghosh Roy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    " - What is Bias Variance Trade off?\n",
    " - Why do we do feature engineering?\n",
    "     - It allows us to take advantage of more features for prediction and allows us to compare things for inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 7 Case Study: Sentiment Analysis\n",
    "\n",
    "## Q) What steps do we take when approaching a dataset?\n",
    "\n",
    " - Find out what kind of problem it is\n",
    " - Get the proper data\n",
    " - Feature Engineering, SVM, Decision Trees, Linear/Logistic Regression\n",
    " \n",
    "## The two main things we want to do is:\n",
    "\n",
    " A) Predict <br>\n",
    " B) Inference\n",
    " \n",
    "-  We will have several models and we choose from them using cross validation\n",
    "-  We fit our models by splitting it, testing and selecting models based on validation\n",
    "-  We choose based on complexity, MSE\n",
    "\n",
    " - Positive and Negative Words\n",
    "    - Goal is to extract a tweet, extract a sentiment based off text/images\n",
    "    \n",
    " - Goal of the session is to analyze tweets from 2016 campaign\n",
    "    - With NLP we want to extract and predict from subjective information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would you take text and predict sentiment?\n",
    "\n",
    "A) We assign weights to words, use polarity based on words obtained from somewhere e.g. Twitter, to analyze classical music reviews, problem is context of the words is missing. Therefore polarity changes with context.\n",
    "   - Problem with dictionaries in these cases is that they are immutable, limited text, and there is bias while making it.\n",
    "   \n",
    "   - We will use IMDB Database (ref slide 7.1)\n",
    "   - We have 25,000 reviews\n",
    "   \n",
    "   ![](eg_of_sentiment_analysis.png)\n",
    "   \n",
    "   - We get text e.g. \"I Love Hanoi\", we take average polarity, if average >0 then sentiment = Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Regression MSE is the ideal measure.\n",
    "## For Classification AUC is the ideal measure\n",
    "\n",
    "- What is AUC?\n",
    "- What is Threshold?\n",
    "    - Where you make a decision to predict of positive class is known as threshold\n",
    "\n",
    "If we are predicting spam, decrease the threshold.\n",
    "\n",
    "| $\\theta$ | Positive Prediction | Negative Prediction |\n",
    "| --- | --- | --- |\n",
    "| True (T) | TP | FN |\n",
    "| False (F) | FP | TN |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ROC.png)\n",
    "\n",
    "## Accuracy is measured using F-1 Score\n",
    "\n",
    "__Precision__ = TP/(TP+FP) - When looking at Threshold\n",
    "\n",
    "example: Asset Managers at Wegmans, you want high precision to be sure someone is stealing\n",
    "\n",
    "__Recall__ = TP/(TP+FN) - When looking at Threshold\n",
    "\n",
    "example: TSA during thanksgiving rush, wants to catch bad guys so low threshold, will ensure high recall\n",
    "\n",
    "![](eg_of_ROC.png)\n",
    "\n",
    "Accuracy must be 99.99% when predicting terrorits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us take a data science approach\n",
    "\n",
    "- Transform text to features\n",
    "- Assign weights to features\n",
    "- Use logistic regression to find proper weights of words\n",
    "- Predict Positive or Negative Sentiment.\n",
    "\n",
    "### Transform text to numbers:\n",
    "    There are many ways to do it, simple common way is,\n",
    "    \n",
    "__TF__ and __IDF__ which is Term Frequency and Inverse Document Frequency respectively\n",
    "\n",
    "- The idea is to assign a feature to each word\n",
    "    - First count unique words, frequency of these words\n",
    "    \n",
    "![](eg_data.png)\n",
    "\n",
    "   - We transform the originial text into:\n",
    "\n",
    "![](word_vector.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do logistic regression, which has both linear and non-linear parts\n",
    "\n",
    "![](logistic_regression.png)\n",
    "\n",
    "   - The more positive words we have the higher Z value and higher the positivity hence, higher the slope.\n",
    "   - For Negative words, the more we have them, the more positive the Z value.\n",
    "   - We notice that Stop Words are of high frequency\n",
    "       - So we create an Inverse Document Frequency\n",
    "\n",
    "![](tf-idf.png)\n",
    "\n",
    "The above equation is from TF-IDF of Scikit Learn i.e ML for Python\n",
    "   - Now we split the weighted matrix of words\n",
    "\n",
    "60% Train  |  30% Validation  |  10% testing\n",
    "\t\n",
    "We use Bernoulli’s Loss Function: $L_\\theta (x,y)$ \n",
    "\n",
    "   - Logistic Regression estimated the weight of each word\n",
    "        - Apply this to IMDB Data\n",
    "\n",
    "We get weights of positive and negative words\n",
    "\n",
    "   - How to interpret Weights? We Divide it by 4\n",
    "    E.G. Octane -7/4 = -1.7 <br>\n",
    "            So if Octane appears in a review, probability of the review to be positive reduces by 170%\n",
    "\n",
    "What is wrong here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERFITTING\n",
    "\n",
    "- The weights are easy to notice, something is wrong in the polynomial not in the logistic regression.\n",
    "- If the model is complex it might be over fitted.\n",
    "- In our case we have 25,000 Reviews which are Data Points\n",
    "- M = 250,000 approximately\n",
    "- Smaller equation than features, this means : Too many features.\n",
    "\n",
    "## To fix this\n",
    "\n",
    "Regularized Logistic Regression\n",
    "\n",
    "    We auto select and eliminate features, it deals with features even if there are many of them.\n",
    "   - We modify loss function by adding a term that penalizes learning, <br> “Don’t Learn Too Much.”.\n",
    "\n",
    "Two ways to penalize data:\n",
    "A) L1 – Ridge <br>\n",
    "B) L2 – Lasso\n",
    "\n",
    "The term added is\n",
    "$\\lambda$  $\\sum_{j=0}\\theta_j^2$\n",
    "\n",
    "The better we fit the data. the smaller the loss.\n",
    "\n",
    "$L(\\theta)_r$= MSE + $\\lambda$  $\\sum_{j=0}\\theta_j^2$\n",
    "\n",
    "if we make $\\lambda$ -> $\\infty$ <br>\n",
    "\n",
    "we penalize everything except the intercept.\n",
    "\n",
    "![](bias_and_variance.png)\n",
    "\n",
    "The problem with L2 Regularization is that even though Stop Words don’t matter they still get some weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](penalization.png)\n",
    "\n",
    "In L1 it is better to find weights exactly ‘0’\n",
    "By Definition L1 cannot learn more features than there are data points\n",
    "Combination of L1 and L2 is Elastic Net Regularization\n",
    "If Alpha = 1 then L1 = 0 and L2 = 1 and vice versa for Alpha = 0\n",
    "Lambda controls how much regularized prediction we need\n",
    "At ‘0’ L1 is undefined.\n",
    "   - Applying 30% L1, 70% L2 and Lambda = 0.02\n",
    "        - We increase performance by 3%\n",
    "    - Now divide the weight by 4\n",
    "\n",
    "For most problems we use Linear + Logistic Regression\n",
    "\n",
    "If dictionary is enough, then Stop.\n",
    "\n",
    "Always use cross validation\n",
    "\n",
    "![](cross_validation.png)\n",
    "\n",
    "Computing confidence in Logistic Regression ( Standard Deviation)\n",
    "![](variance_of_bernauli.png)\n",
    "\n",
    "Problem with generalizability exists since IMDB database was used to train and the data was actually Twitter Data.\n",
    "\n",
    "After tokenizing words in sentiment analysis notebook, It converts text into numbers, then we construct a pipeline to create a TF.\n",
    "\n",
    "There are special objects in Spark that allow you to compute performance measures.\n",
    "\n",
    "Evaluate object on prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
