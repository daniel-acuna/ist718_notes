{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accesing Model Accuracy- Feb 19/20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Decomposition- Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ LHS=E[(y-\\hat f(x))^2] = E[(f(x) + \\epsilon + \\hat f(x))^2]$ <br>\n",
    "$ =E[(f(x) + \\epsilon - \\hat f(x) + E[\\hat f(x)]-E[\\hat f(x)])^2]$<br>\n",
    "  ### Using formula $(a+b+c)^2= a^2+b^2+c^2+2ab+2bc+2ca$\n",
    "$ LHS=E[(f(x) +-E[\\hat f(x)])^2 +(E[\\hat f(x)]-\\hat f(x))^2 + \\epsilon^2 + 2((f(x)-E[\\hat f(x)])(E[\\hat f(x)]-\\hat f(x))+2(E[\\hat f(x)]-\\hat f(x))(\\epsilon)+ 2(\\epsilon)(f(x)-E[\\hat f(x)])]$<br> \n",
    "  ### Using formula $E[f(x)+g(x)]=E[f(x)]+E[g(x)]$ we get:\n",
    "$ LHS=E[(f(x) +-E[\\hat f(x)])]^2 +E[(E[\\hat f(x)]-\\hat f(x))]^2 + E[\\epsilon]^2 + 2E[((f(x)-E[\\hat f(x)])(E[\\hat f(x)]-\\hat f(x))]+2E[(E[\\hat f(x)]-\\hat f(x))(\\epsilon)]+ 2E[(\\epsilon)(f(x)-E[\\hat f(x)])]$<br> \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By breaking down $LHS$ such that $LHS=T1+T2+T3+T4+T5$, we get:\n",
    "$T1=E[(f(x) +-E[\\hat f(x)])]^2$<br>\n",
    "$T2=E[(E[\\hat f(x)]-\\hat f(x))]^2$<br>\n",
    "$T3=E[\\epsilon]^2$<br>\n",
    "$T4=2E[((f(x)-E[\\hat f(x)])(E[\\hat f(x)]-\\hat f(x))]$<br>\n",
    "$T5=2E[(E[\\hat f(x)]-\\hat f(x))(\\epsilon)]$<br>\n",
    "$T6=2E[(\\epsilon)(f(x)-E[\\hat f(x)])]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $T1$ is $(bias)^2$\n",
    "### $T2$ is variance in output\n",
    "### Since $E[\\epsilon]=0$, $T3$ can be rewritten as:\n",
    "$T3=E[\\epsilon-E[\\epsilon]^2]$ \n",
    "### $T3$ is variance in error $\\sigma_{\\epsilon}^2$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In $T4=2E[((f(x)-E[\\hat f(x)])(E[\\hat f(x)]-\\hat f(x))]$, \n",
    "consider the second term-  $(E[\\hat f(x)]-\\hat f(x))$<br>\n",
    "here $E[\\hat f(x)]$ is a constant$=\\hat f(x)$ and $E[constant]=constant$,<br> so $E[\\hat f(x)]=\\hat f(x)$<br>\n",
    "\n",
    "On substituting this the second term becomes:<br>\n",
    "$(\\hat f(x)-\\hat f(x))=0$<br>\n",
    "\n",
    "### Therefore, $T4=E[0]=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using formula, $E[f(x)g(x)]=E[f(x)]E[g(x)]+2cov(f(x),g(x))$, we get:\n",
    "$T5=2(E[(E[\\hat f(x)]-\\hat f(x))]E[(\\epsilon)]+2cov((E[\\hat f(x)]-\\hat f(x)),(\\epsilon)))$<br>\n",
    "$cov=0$ since we assume that the error is independent of the function<br>\n",
    "also, $E(\\epsilon)=0$<br>\n",
    "### Therefore, $T5=0$ and Similarly $T6=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, \n",
    "$LHS=T1+T2+T3=E[(f(x) +-E[\\hat f(x)])]^2+E[(E[\\hat f(x)]-\\hat f(x))]^2+E[\\epsilon]^2$<br>\n",
    "$=(bias)^2+variance+\\sigma_{\\epsilon}^2$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
